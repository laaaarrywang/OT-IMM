{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Time-Indexed RealNVP Implementation\n",
    "\n",
    "This notebook comprehensively tests the time-indexed RealNVP flow T(t, x) for:\n",
    "1. **Invertibility**: T^{-1}(t, T(t, x)) = x\n",
    "2. **Differentiability w.r.t. time**: ∂T/∂t exists and is smooth\n",
    "3. **Differentiability w.r.t. input**: ∂T/∂x exists with correct Jacobian\n",
    "4. **Log-determinant consistency**: log|det(∂T/∂x)| matches forward and inverse\n",
    "5. **Multiple scales**: From tiny 8×8 to ImageNet 224×224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from realnvp import TimeIndexedRealNVP, create_vector_flow, create_mnist_flow,create_cifar10_flow, create_imagenet_flow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Count Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_params(model):\n",
    "    n = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    mb = n * 4 / 1e6  # float32\n",
    "    return n, mb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Invertibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def check_invertibility(model, x, t, name, atol=1e-5, rtol=1e-5):\n",
    "    model.eval()\n",
    "    y, ld1 = model(x, t)\n",
    "    x_rec, ld2 = model.inverse(y, t)\n",
    "\n",
    "    diff = (x_rec - x).reshape(x.shape[0], -1)\n",
    "    l2 = diff.norm(dim=1)\n",
    "    linf = diff.abs().max(dim=1).values\n",
    "    rel = l2 / (x.reshape(x.shape[0], -1).norm(dim=1) + 1e-12)\n",
    "\n",
    "    # logdet from inverse should be the negative of forward\n",
    "    logdet_consistency = (ld1 + ld2).abs()\n",
    "\n",
    "    print(f\"\\n[{name}] Invertibility check\")\n",
    "    print(f\"  ||x_rec - x||_2    : mean {l2.mean():.3e} | max {l2.max():.3e}\")\n",
    "    print(f\"  ||x_rec - x||_inf  : mean {linf.mean():.3e} | max {linf.max():.3e}\")\n",
    "    print(f\"  rel L2 error       : mean {rel.mean():.3e} | max {rel.max():.3e}\")\n",
    "    print(f\"  |logdet + logdet^-1|: mean {logdet_consistency.mean():.3e} | max {logdet_consistency.max():.3e}\")\n",
    "\n",
    "    ok = (l2.max() < atol + rtol * x.abs().max()) and (logdet_consistency.max() < 1e-4)    \n",
    "    print(f\"  PASS: {ok}\")\n",
    "    return ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Differentiability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_differentiability_t(model, x, name, eps_list=(1e-1, 3e-2, 1e-2, 3e-3, 1e-3)):\n",
    "    model.eval()\n",
    "    B = x.shape[0]\n",
    "    device = x.device\n",
    "    D = x.view(B, -1).shape[1]  # Total dimension\n",
    "    \n",
    "    # random t in [0,1]\n",
    "    t = torch.rand(B, device=device, dtype=x.dtype, requires_grad=True)\n",
    "\n",
    "    # Autograd gradient of sum(y_i) w.r.t. t_i (per-sample)\n",
    "    y, _ = model(x, t)\n",
    "    f = y.view(B, -1).sum(dim=1)          # [B]\n",
    "    g_aut, = torch.autograd.grad(f.sum(), t, create_graph=False)  # [B]\n",
    "    \n",
    "    # Per-element gradients (normalized by dimension)\n",
    "    g_aut_per_elem = g_aut / D\n",
    "\n",
    "    print(f\"\\n[{name}] Differentiability in time: autograd vs finite-difference\")\n",
    "    print(f\"  Dimension: {D:,}\")\n",
    "    print(f\"  Total grad stats: mean {g_aut.mean().item():.3e} | std {g_aut.std().item():.3e}\")\n",
    "    print(f\"  Per-elem grad:    mean {g_aut_per_elem.mean().item():.3e} | std {g_aut_per_elem.std().item():.3e}\")\n",
    "\n",
    "    # Finite differences\n",
    "    with torch.no_grad():\n",
    "        for eps in eps_list:\n",
    "            t_plus = (t.detach() + eps).clamp(0.0, 1.0)\n",
    "            y_plus, _ = model(x, t_plus)\n",
    "            fd = (y_plus - y.detach()) / eps        # same shape as y\n",
    "            fd_sum = fd.view(B, -1).sum(dim=1)      # [B]\n",
    "\n",
    "            abs_err = (fd_sum - g_aut.detach()).abs()\n",
    "            rel_err = abs_err / (g_aut.detach().abs() + 1e-12)\n",
    "            \n",
    "            # Per-element errors\n",
    "            abs_err_per_elem = abs_err / D\n",
    "            rel_err_per_elem = rel_err  # relative error doesn't change with normalization\n",
    "\n",
    "            print(f\"  eps={eps:>7.1e} | total_err {abs_err.mean():.3e} | \"\n",
    "                  f\"per_elem_err {abs_err_per_elem.mean():.3e} | rel_err {rel_err_per_elem.mean():.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset-specific runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_run_imagenet(device=\"cpu\"):\n",
    "    print(\"\\n=== IMAGENET-LIKE IMAGE FLOW ===\")\n",
    "    model = create_imagenet_flow(\n",
    "        resolution=128,  # Smaller than default 224 for memory efficiency\n",
    "        num_layers=4, time_embed_dim=256,\n",
    "        img_base_channels=128, img_blocks=3, img_groups=32,\n",
    "        img_log_scale_clamp=10.0, use_permutation=True\n",
    "    ).to(device)\n",
    "    nparams, mb = count_params(model)\n",
    "    print(f\"Params: {nparams:,} ({mb:.2f} MB)\")\n",
    "    x = torch.randn(4, 3, 128, 128, device=device)  # Very small batch for memory\n",
    "    t = torch.rand(4, device=device)\n",
    "    check_invertibility(model, x, t, \"ImageNet (3x128x128)\")\n",
    "    check_differentiability_t(model, x, \"ImageNet (3x128x128)\")\n",
    "\n",
    "def quick_run_imagenet_full(device=\"cpu\"):\n",
    "    print(\"\\n=== FULL IMAGENET FLOW ===\")\n",
    "    model = create_imagenet_flow(\n",
    "        resolution=224,  # Full resolution\n",
    "        num_layers=6, time_embed_dim=512,\n",
    "        img_base_channels=256, img_blocks=4, img_groups=32,\n",
    "        img_log_scale_clamp=10.0, use_permutation=True\n",
    "    ).to(device)\n",
    "    nparams, mb = count_params(model)\n",
    "    print(f\"Params: {nparams:,} ({mb:.2f} MB)\")\n",
    "    x = torch.randn(4, 3, 224, 224, device=device)\n",
    "    t = torch.rand(4, device=device)\n",
    "    check_invertibility(model, x, t, \"ImageNet (3x224x224)\")\n",
    "    check_differentiability_t(model, x, \"ImageNet (3x224x224)\")\n",
    "\n",
    "def quick_run_vector(device=\"cpu\"):\n",
    "    print(\"\\n=== VECTOR FLOW ===\")\n",
    "    model = create_vector_flow(\n",
    "        dim=32, num_layers=6, time_embed_dim=64,\n",
    "        hidden=512, mlp_blocks=3, activation=\"gelu\",\n",
    "        use_layernorm=False, use_permutation=True\n",
    "    ).to(device)\n",
    "    nparams, mb = count_params(model)\n",
    "    print(f\"Params: {nparams:,} ({mb:.2f} MB)\")\n",
    "    x = torch.randn(8, 32, device=device)\n",
    "    t = torch.rand(8, device=device)\n",
    "    check_invertibility(model, x, t, \"vector(32)\")\n",
    "    check_differentiability_t(model, x, \"vector(32)\")\n",
    "\n",
    "def quick_run_mnist_like(device=\"cpu\"):\n",
    "    print(\"\\n=== MNIST-LIKE IMAGE FLOW ===\")\n",
    "    model = create_mnist_flow(\n",
    "        image_mode=True, num_layers=6, time_embed_dim=128,\n",
    "        img_base_channels=96, img_blocks=3, img_groups=32,\n",
    "        img_log_scale_clamp=10.0, use_permutation=True\n",
    "    ).to(device)\n",
    "    nparams, mb = count_params(model)\n",
    "    print(f\"Params: {nparams:,} ({mb:.2f} MB)\")\n",
    "    x = torch.randn(4, 1, 28, 28, device=device)\n",
    "    t = torch.rand(4, device=device)\n",
    "    check_invertibility(model, x, t, \"MNIST (1x28x28)\")\n",
    "    check_differentiability_t(model, x, \"MNIST (1x28x28)\")\n",
    "\n",
    "def quick_run_cifar(device=\"cpu\"):\n",
    "    print(\"\\n=== CIFAR-10 IMAGE FLOW ===\")\n",
    "    model = create_cifar10_flow(\n",
    "        num_layers=8, time_embed_dim=128,\n",
    "        img_base_channels=128, img_blocks=4, img_groups=32,\n",
    "        img_log_scale_clamp=10.0, use_permutation=True\n",
    "    ).to(device)\n",
    "    nparams, mb = count_params(model)\n",
    "    print(f\"Params: {nparams:,} ({mb:.2f} MB)\")\n",
    "    x = torch.randn(4, 3, 32, 32, device=device)  # keep small batch for speed\n",
    "    t = torch.rand(4, device=device)\n",
    "    check_invertibility(model, x, t, \"CIFAR (3x32x32)\")\n",
    "    check_differentiability_t(model, x, \"CIFAR (3x32x32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "=== VECTOR FLOW ===\n",
      "Params: 3,499,200 (14.00 MB)\n",
      "\n",
      "[vector(32)] Invertibility check\n",
      "  ||x_rec - x||_2    : mean 2.484e-07 | max 4.971e-07\n",
      "  ||x_rec - x||_inf  : mean 1.788e-07 | max 4.768e-07\n",
      "  rel L2 error       : mean 4.306e-08 | max 7.834e-08\n",
      "  |logdet + logdet^-1|: mean 7.153e-07 | max 9.537e-07\n",
      "  PASS: True\n",
      "\n",
      "[vector(32)] Differentiability in time: autograd vs finite-difference\n",
      "  Dimension: 32\n",
      "  Total grad stats: mean 2.346e+00 | std 6.113e+01\n",
      "  Per-elem grad:    mean 7.331e-02 | std 1.910e+00\n",
      "  eps=1.0e-01 | total_err 4.944e+01 | per_elem_err 1.545e+00 | rel_err 1.008e+00\n",
      "  eps=3.0e-02 | total_err 4.999e+01 | per_elem_err 1.562e+00 | rel_err 1.012e+00\n",
      "  eps=1.0e-02 | total_err 5.002e+01 | per_elem_err 1.563e+00 | rel_err 1.017e+00\n",
      "  eps=3.0e-03 | total_err 4.987e+01 | per_elem_err 1.558e+00 | rel_err 1.018e+00\n",
      "  eps=1.0e-03 | total_err 6.285e+01 | per_elem_err 1.964e+00 | rel_err 1.251e+00\n",
      "\n",
      "=== MNIST-LIKE IMAGE FLOW ===\n",
      "Params: 3,463,500 (13.85 MB)\n",
      "\n",
      "[MNIST (1x28x28)] Invertibility check\n",
      "  ||x_rec - x||_2    : mean 1.591e-05 | max 1.668e-05\n",
      "  ||x_rec - x||_inf  : mean 2.663e-06 | max 3.260e-06\n",
      "  rel L2 error       : mean 5.521e-07 | max 5.795e-07\n",
      "  |logdet + logdet^-1|: mean 1.526e-05 | max 3.052e-05\n",
      "  PASS: True\n",
      "\n",
      "[MNIST (1x28x28)] Differentiability in time: autograd vs finite-difference\n",
      "  Dimension: 784\n",
      "  Total grad stats: mean 2.215e+04 | std 5.819e+05\n",
      "  Per-elem grad:    mean 2.825e+01 | std 7.423e+02\n",
      "  eps=1.0e-01 | total_err 4.257e+05 | per_elem_err 5.429e+02 | rel_err 1.009e+00\n",
      "  eps=3.0e-02 | total_err 4.286e+05 | per_elem_err 5.467e+02 | rel_err 1.038e+00\n",
      "  eps=1.0e-02 | total_err 4.309e+05 | per_elem_err 5.496e+02 | rel_err 1.033e+00\n",
      "  eps=3.0e-03 | total_err 3.775e+05 | per_elem_err 4.814e+02 | rel_err 9.123e-01\n",
      "  eps=1.0e-03 | total_err 4.291e+05 | per_elem_err 5.473e+02 | rel_err 1.661e+00\n",
      "\n",
      "=== CIFAR-10 IMAGE FLOW ===\n",
      "Params: 10,611,760 (42.45 MB)\n",
      "\n",
      "[CIFAR (3x32x32)] Invertibility check\n",
      "  ||x_rec - x||_2    : mean 6.891e-05 | max 7.376e-05\n",
      "  ||x_rec - x||_inf  : mean 5.864e-06 | max 6.557e-06\n",
      "  rel L2 error       : mean 1.254e-06 | max 1.350e-06\n",
      "  |logdet + logdet^-1|: mean 6.104e-05 | max 1.221e-04\n",
      "  PASS: False\n",
      "\n",
      "[CIFAR (3x32x32)] Differentiability in time: autograd vs finite-difference\n",
      "  Dimension: 3,072\n",
      "  Total grad stats: mean 4.337e+05 | std 3.006e+05\n",
      "  Per-elem grad:    mean 1.412e+02 | std 9.784e+01\n",
      "  eps=1.0e-01 | total_err 4.462e+05 | per_elem_err 1.452e+02 | rel_err 9.023e-01\n",
      "  eps=3.0e-02 | total_err 4.542e+05 | per_elem_err 1.479e+02 | rel_err 1.021e+00\n",
      "  eps=1.0e-02 | total_err 4.782e+05 | per_elem_err 1.557e+02 | rel_err 2.168e+00\n",
      "  eps=3.0e-03 | total_err 4.785e+05 | per_elem_err 1.557e+02 | rel_err 2.991e+00\n",
      "  eps=1.0e-03 | total_err 7.110e+05 | per_elem_err 2.314e+02 | rel_err 1.049e+01\n",
      "\n",
      "=== IMAGENET-LIKE IMAGE FLOW ===\n",
      "Params: 4,384,280 (17.54 MB)\n",
      "\n",
      "[ImageNet (3x128x128)] Invertibility check\n",
      "  ||x_rec - x||_2    : mean 1.175e-04 | max 1.175e-04\n",
      "  ||x_rec - x||_inf  : mean 2.861e-06 | max 2.861e-06\n",
      "  rel L2 error       : mean 5.301e-07 | max 5.301e-07\n",
      "  |logdet + logdet^-1|: mean 0.000e+00 | max 0.000e+00\n",
      "  PASS: False\n",
      "\n",
      "[ImageNet (3x128x128)] Differentiability in time: autograd vs finite-difference\n",
      "  Dimension: 49,152\n",
      "  Total grad stats: mean 1.978e+07 | std nan\n",
      "  Per-elem grad:    mean 4.024e+02 | std nan\n",
      "  eps=1.0e-01 | total_err 1.997e+07 | per_elem_err 4.062e+02 | rel_err 1.010e+00\n",
      "  eps=3.0e-02 | total_err 1.972e+07 | per_elem_err 4.011e+02 | rel_err 9.969e-01\n",
      "  eps=1.0e-02 | total_err 2.034e+07 | per_elem_err 4.138e+02 | rel_err 1.028e+00\n",
      "  eps=3.0e-03 | total_err 2.569e+07 | per_elem_err 5.227e+02 | rel_err 1.299e+00\n",
      "  eps=1.0e-03 | total_err 1.849e+07 | per_elem_err 3.762e+02 | rel_err 9.349e-01\n",
      "\n",
      "=== FULL IMAGENET FLOW ===\n",
      "Params: 34,791,972 (139.17 MB)\n",
      "\n",
      "[ImageNet (3x224x224)] Invertibility check\n",
      "  ||x_rec - x||_2    : mean 4.243e-04 | max 4.243e-04\n",
      "  ||x_rec - x||_inf  : mean 7.868e-06 | max 7.868e-06\n",
      "  rel L2 error       : mean 1.095e-06 | max 1.095e-06\n",
      "  |logdet + logdet^-1|: mean 3.906e-03 | max 3.906e-03\n",
      "  PASS: False\n",
      "\n",
      "[ImageNet (3x224x224)] Differentiability in time: autograd vs finite-difference\n",
      "  Dimension: 150,528\n",
      "  Total grad stats: mean 8.010e+05 | std nan\n",
      "  Per-elem grad:    mean 5.322e+00 | std nan\n",
      "  eps=1.0e-01 | total_err 8.738e+05 | per_elem_err 5.805e+00 | rel_err 1.091e+00\n",
      "  eps=3.0e-02 | total_err 2.857e+05 | per_elem_err 1.898e+00 | rel_err 3.566e-01\n",
      "  eps=1.0e-02 | total_err 1.933e+06 | per_elem_err 1.284e+01 | rel_err 2.413e+00\n",
      "  eps=3.0e-03 | total_err 4.859e+06 | per_elem_err 3.228e+01 | rel_err 6.065e+00\n",
      "  eps=1.0e-03 | total_err 4.178e+06 | per_elem_err 2.776e+01 | rel_err 5.216e+00\n",
      "\n",
      "All checks done.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "quick_run_vector(device)\n",
    "quick_run_mnist_like(device)\n",
    "quick_run_cifar(device)\n",
    "quick_run_imagenet(device)\n",
    "quick_run_imagenet_full(device)\n",
    "print(\"\\nAll checks done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb-fbsde-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
